{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "conscious-craft",
   "metadata": {},
   "source": [
    "# Imports and Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "successful-relative",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# basics\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# sklearn\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "\n",
    "# keras\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.callbacks import TensorBoard, ModelCheckpoint\n",
    "\n",
    "# tensorflow\n",
    "import tensorflow as tf\n",
    "\n",
    "# plotting\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# local\n",
    "from data_loaders import load_mnist_data, load_iris_data, retrieve_predictions\n",
    "from models import *\n",
    "from utils import train_model_iteratively, get_model_weights, convert_weight_dict_to_dataframe\n",
    "\n",
    "plt.style.use('ggplot')\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "organic-amendment",
   "metadata": {},
   "outputs": [],
   "source": [
    "# suppress warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "optional-irish",
   "metadata": {},
   "source": [
    "# Working examples that use module functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "national-kidney",
   "metadata": {},
   "source": [
    "## MNIST working example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "seven-statement",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_mnist, y_train_mnist, x_test_mnist, y_test_mnist = load_mnist_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fallen-heath",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(y_test_mnist).to_csv(\"y_test_mnist.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "desirable-recall",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"mnist_test\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 26, 26, 2)         20        \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 3, 3, 2)           0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 3, 3, 2)           0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 18)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 2)                 38        \n",
      "=================================================================\n",
      "Total params: 58\n",
      "Trainable params: 58\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "baseline_mnist_model(name='mnist_test', num_classes=2).summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "worst-savage",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: (12665, 28, 28, 1), Y_train: (12665, 2)\n",
      "X_test: (100, 28, 28, 1), Y_test: (100, 2)\n"
     ]
    }
   ],
   "source": [
    "example_mnist_outdir = './data/example_mnist'\n",
    "train_model_iteratively(baseline_model=baseline_mnist_model,\n",
    "                        X_train=x_train_mnist, Y_train=y_train_mnist, \n",
    "                        X_test=x_test_mnist, Y_test=y_test_mnist,\n",
    "                        outdir=example_mnist_outdir, epochs=4, epochs_to_save=None, \n",
    "                        batch_size=128, num_models=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "average-vertex",
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_preds = retrieve_mnist_preds(y_test=y_test_mnist, outdir=example_mnist_outdir)\n",
    "mnist_weights = convert_weight_dict_to_dataframe(get_model_weights(example_mnist_outdir))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cross-october",
   "metadata": {},
   "source": [
    "## IRIS working example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "starting-timing",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_iris, x_test_iris, y_train_iris, y_test_iris = load_iris_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "academic-george",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(y_test_iris).to_csv(\"y_test_iris.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "responsible-impression",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"iris_test\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_11 (Dense)             (None, 3)                 9         \n",
      "=================================================================\n",
      "Total params: 9\n",
      "Trainable params: 9\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "baseline_iris_model(name='iris_test').summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "loaded-butterfly",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: (75, 2), Y_train: (75, 3)\n",
      "X_test: (75, 2), Y_test: (75, 3)\n"
     ]
    }
   ],
   "source": [
    "example_iris_outdir = './data/example_iris'\n",
    "\n",
    "# need this to suppress tf.function retracing warning that kept coming up\n",
    "tf.compat.v1.logging.set_verbosity(\"ERROR\")\n",
    "train_model_iteratively(baseline_model=baseline_iris_model,\n",
    "                        X_train=x_train_iris, Y_train=y_train_iris, \n",
    "                        X_test=x_test_iris, Y_test=y_test_iris,\n",
    "                        outdir=example_iris_outdir, epochs=15, epochs_to_save=None, \n",
    "                        batch_size=5, num_models=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dietary-label",
   "metadata": {},
   "source": [
    "# Model Runs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "changing-intelligence",
   "metadata": {},
   "source": [
    "## MNIST model runs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aggregate-ceiling",
   "metadata": {},
   "source": [
    "### Baseline MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "oriented-detroit",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: (12665, 28, 28, 1), Y_train: (12665, 2)\n",
      "X_test: (100, 28, 28, 1), Y_test: (100, 2)\n",
      "train_model_iteratively took 347.0760819911957 seconds\n",
      "\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "train_model_iteratively(baseline_model=baseline_mnist_model,\n",
    "                        X_train=x_train_mnist, Y_train=y_train_mnist, \n",
    "                        X_test=x_test_mnist, Y_test=y_test_mnist,\n",
    "                        outdir=\"./data/mnist_baseline\", epochs=4, epochs_to_save=None, \n",
    "                        batch_size=128, num_models=100)\n",
    "print(\"train_model_iteratively took {} seconds\\n\".format(time.time() - start))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "expressed-retrieval",
   "metadata": {},
   "source": [
    "### Sweep epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "typical-destruction",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: (12665, 28, 28, 1), Y_train: (12665, 2)\n",
      "X_test: (100, 28, 28, 1), Y_test: (100, 2)\n",
      "train_model_iteratively took 637.4080867767334 seconds\n",
      "\n",
      "X_train: (12665, 28, 28, 1), Y_train: (12665, 2)\n",
      "X_test: (100, 28, 28, 1), Y_test: (100, 2)\n",
      "train_model_iteratively took 923.3448550701141 seconds\n",
      "\n",
      "X_train: (12665, 28, 28, 1), Y_train: (12665, 2)\n",
      "X_test: (100, 28, 28, 1), Y_test: (100, 2)\n",
      "train_model_iteratively took 1249.7377841472626 seconds\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for num_epochs in [8, 12, 16]:\n",
    "    outdir = \"./data/mnist_epoch_{}\".format(num_epochs)\n",
    "    start = time.time()\n",
    "    train_model_iteratively(baseline_model=baseline_mnist_model,\n",
    "                            X_train=x_train_mnist, Y_train=y_train_mnist, \n",
    "                            X_test=x_test_mnist, Y_test=y_test_mnist,\n",
    "                            outdir=outdir, epochs=num_epochs, epochs_to_save=None, \n",
    "                            batch_size=128, num_models=100)\n",
    "    print(\"train_model_iteratively took {} seconds\\n\".format(time.time() - start))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "elder-tracy",
   "metadata": {},
   "source": [
    "### Sweep batch size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "limited-adrian",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: (12665, 28, 28, 1), Y_train: (12665, 2)\n",
      "X_test: (100, 28, 28, 1), Y_test: (100, 2)\n",
      "train_model_iteratively took 821.0129718780518 seconds\n",
      "\n",
      "X_train: (12665, 28, 28, 1), Y_train: (12665, 2)\n",
      "X_test: (100, 28, 28, 1), Y_test: (100, 2)\n",
      "train_model_iteratively took 459.6735169887543 seconds\n",
      "\n",
      "X_train: (12665, 28, 28, 1), Y_train: (12665, 2)\n",
      "X_test: (100, 28, 28, 1), Y_test: (100, 2)\n",
      "train_model_iteratively took 303.78163290023804 seconds\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for batch_size in [32, 64, 256]:\n",
    "    outdir = \"./data/mnist_batch_{}\".format(batch_size)\n",
    "    start = time.time()\n",
    "    train_model_iteratively(baseline_model=baseline_mnist_model,\n",
    "                            X_train=x_train_mnist, Y_train=y_train_mnist, \n",
    "                            X_test=x_test_mnist, Y_test=y_test_mnist,\n",
    "                            outdir=outdir, epochs=4, epochs_to_save=None, \n",
    "                            batch_size=batch_size, num_models=100)\n",
    "    print(\"train_model_iteratively took {} seconds\\n\".format(time.time() - start))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "outer-texture",
   "metadata": {},
   "source": [
    "### Sweep layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "acquired-calendar",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: (12665, 28, 28, 1), Y_train: (12665, 2)\n",
      "X_test: (100, 28, 28, 1), Y_test: (100, 2)\n",
      "train_model_iteratively took 559.6651039123535 seconds\n",
      "\n",
      "X_train: (12665, 28, 28, 1), Y_train: (12665, 2)\n",
      "X_test: (100, 28, 28, 1), Y_test: (100, 2)\n",
      "train_model_iteratively took 788.8657438755035 seconds\n",
      "\n",
      "X_train: (12665, 28, 28, 1), Y_train: (12665, 2)\n",
      "X_test: (100, 28, 28, 1), Y_test: (100, 2)\n",
      "train_model_iteratively took 932.9938669204712 seconds\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for idx, model in enumerate([mnist_2_layers, mnist_3_layers, mnist_4_layers]):\n",
    "    outdir = \"./data/mnist_layers_{}\".format(idx+2)\n",
    "    start = time.time()\n",
    "    train_model_iteratively(baseline_model=model,\n",
    "                            X_train=x_train_mnist, Y_train=y_train_mnist, \n",
    "                            X_test=x_test_mnist, Y_test=y_test_mnist,\n",
    "                            outdir=outdir, epochs=4, epochs_to_save=None, \n",
    "                            batch_size=128, num_models=100)\n",
    "    print(\"train_model_iteratively took {} seconds\\n\".format(time.time() - start))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "trained-guard",
   "metadata": {},
   "source": [
    "## IRIS model runs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "african-current",
   "metadata": {},
   "source": [
    "### Baseline IRIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dominant-helicopter",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: (75, 2), Y_train: (75, 3)\n",
      "X_test: (75, 2), Y_test: (75, 3)\n",
      "train_model_iteratively took 774.9198100566864 seconds\n",
      "\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "train_model_iteratively(baseline_model=baseline_iris_model,\n",
    "                        X_train=x_train_iris, Y_train=y_train_iris, \n",
    "                        X_test=x_test_iris, Y_test=y_test_iris,\n",
    "                        outdir=\"./data/iris_baseline\", epochs=150, epochs_to_save=None, \n",
    "                        batch_size=5, num_models=100)\n",
    "print(\"train_model_iteratively took {} seconds\\n\".format(time.time() - start))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "incorrect-crossing",
   "metadata": {},
   "source": [
    "### Sweep epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "southeast-entertainment",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: (75, 2), Y_train: (75, 3)\n",
      "X_test: (75, 2), Y_test: (75, 3)\n",
      "train_model_iteratively took 507.4716958999634 seconds\n",
      "\n",
      "X_train: (75, 2), Y_train: (75, 3)\n",
      "X_test: (75, 2), Y_test: (75, 3)\n",
      "train_model_iteratively took 1513.5248148441315 seconds\n",
      "\n",
      "X_train: (75, 2), Y_train: (75, 3)\n",
      "X_test: (75, 2), Y_test: (75, 3)\n",
      "train_model_iteratively took 2045.6344740390778 seconds\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for num_epochs in [100, 300, 450]:\n",
    "    outdir = \"./data/iris_epoch_{}\".format(num_epochs)\n",
    "    start = time.time()\n",
    "    train_model_iteratively(baseline_model=baseline_iris_model,\n",
    "                            X_train=x_train_iris, Y_train=y_train_iris, \n",
    "                            X_test=x_test_iris, Y_test=y_test_iris,\n",
    "                            outdir=outdir, epochs=num_epochs, epochs_to_save=None, \n",
    "                            batch_size=5, num_models=100)\n",
    "    print(\"train_model_iteratively took {} seconds\\n\".format(time.time() - start))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "final-governor",
   "metadata": {},
   "source": [
    "### Sweep batch size: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ambient-privacy",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: (75, 2), Y_train: (75, 3)\n",
      "X_test: (75, 2), Y_test: (75, 3)\n",
      "train_model_iteratively took 668.1161737442017 seconds\n",
      "\n",
      "X_train: (75, 2), Y_train: (75, 3)\n",
      "X_test: (75, 2), Y_test: (75, 3)\n",
      "train_model_iteratively took 741.2695188522339 seconds\n",
      "\n",
      "X_train: (75, 2), Y_train: (75, 3)\n",
      "X_test: (75, 2), Y_test: (75, 3)\n",
      "train_model_iteratively took 589.3309698104858 seconds\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for batch_size in [10, 20, 40]:\n",
    "    outdir = \"./data/iris_batch_{}\".format(batch_size)\n",
    "    start = time.time()\n",
    "    train_model_iteratively(baseline_model=baseline_iris_model,\n",
    "                            X_train=x_train_iris, Y_train=y_train_iris, \n",
    "                            X_test=x_test_iris, Y_test=y_test_iris,\n",
    "                            outdir=outdir, epochs=150, epochs_to_save=None, \n",
    "                            batch_size=batch_size, num_models=100)\n",
    "    print(\"train_model_iteratively took {} seconds\\n\".format(time.time() - start))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "reverse-performer",
   "metadata": {},
   "source": [
    "### Sweep layers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "express-queens",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: (75, 2), Y_train: (75, 3)\n",
      "X_test: (75, 2), Y_test: (75, 3)\n",
      "train_model_iteratively took 726.9213287830353 seconds\n",
      "\n",
      "X_train: (75, 2), Y_train: (75, 3)\n",
      "X_test: (75, 2), Y_test: (75, 3)\n",
      "train_model_iteratively took 773.2967009544373 seconds\n",
      "\n",
      "X_train: (75, 2), Y_train: (75, 3)\n",
      "X_test: (75, 2), Y_test: (75, 3)\n",
      "train_model_iteratively took 769.7694590091705 seconds\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for idx, model in enumerate([iris_2_layers, iris_3_layers, iris_4_layers]):\n",
    "    outdir = \"./data/iris_layers_{}\".format(idx+2)\n",
    "    start = time.time()\n",
    "    train_model_iteratively(baseline_model=model,\n",
    "                            X_train=x_train_iris, Y_train=y_train_iris, \n",
    "                            X_test=x_test_iris, Y_test=y_test_iris,\n",
    "                            outdir=outdir, epochs=150, epochs_to_save=None, \n",
    "                            batch_size=5, num_models=100)\n",
    "    print(\"train_model_iteratively took {} seconds\\n\".format(time.time() - start))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ideal-uniform",
   "metadata": {},
   "source": [
    "### Sweep nodes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cellular-variable",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: (75, 2), Y_train: (75, 3)\n",
      "X_test: (75, 2), Y_test: (75, 3)\n",
      "train_model_iteratively took 720.6743988990784 seconds\n",
      "\n",
      "X_train: (75, 2), Y_train: (75, 3)\n",
      "X_test: (75, 2), Y_test: (75, 3)\n",
      "train_model_iteratively took 726.2040410041809 seconds\n",
      "\n",
      "X_train: (75, 2), Y_train: (75, 3)\n",
      "X_test: (75, 2), Y_test: (75, 3)\n",
      "train_model_iteratively took 729.7382500171661 seconds\n",
      "\n",
      "X_train: (75, 2), Y_train: (75, 3)\n",
      "X_test: (75, 2), Y_test: (75, 3)\n",
      "train_model_iteratively took 765.2918190956116 seconds\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for idx, model in enumerate([iris_3_nodes, iris_4_nodes, iris_5_nodes, iris_6_nodes]):\n",
    "    outdir = \"./data/iris_nodes_{}\".format(idx+3)\n",
    "    start = time.time()\n",
    "    train_model_iteratively(baseline_model=model,\n",
    "                            X_train=x_train_iris, Y_train=y_train_iris, \n",
    "                            X_test=x_test_iris, Y_test=y_test_iris,\n",
    "                            outdir=outdir, epochs=150, epochs_to_save=None, \n",
    "                            batch_size=5, num_models=100)\n",
    "    print(\"train_model_iteratively took {} seconds\\n\".format(time.time() - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "higher-document",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:deep_chaos] *",
   "language": "python",
   "name": "conda-env-deep_chaos-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
