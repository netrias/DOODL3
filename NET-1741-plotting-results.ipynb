{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "wireless-constitution",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# basics\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# scipy and sklearn\n",
    "from scipy.stats import entropy\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "\n",
    "# plotting\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "import seaborn as sns\n",
    "from IPython.display import Image\n",
    "from matplotlib.patches import Rectangle\n",
    "\n",
    "# CMDGB\n",
    "from CMGDB import PlotMorseSets, PlotMorseGraph\n",
    "\n",
    "# local\n",
    "from data_loaders import retrieve_predictions\n",
    "from models import *\n",
    "from utils import get_model_weights, convert_weight_dict_to_dataframe, compute_morse_graph, \\\n",
    "                  compute_morse_graph_with_gpflow_gp, compute_order_retraction\n",
    "\n",
    "sns.set()\n",
    "plt.style.use('ggplot')\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "opened-reproduction",
   "metadata": {},
   "outputs": [],
   "source": [
    "# suppress warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "anonymous-iraqi",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_mnist = np.array(pd.read_csv(\"y_test_mnist.csv\"))\n",
    "y_test_iris = np.array(pd.read_csv(\"y_test_iris.csv\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "passive-wayne",
   "metadata": {},
   "source": [
    "# Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "accurate-schedule",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plots_mnist(df_with_stats, y=\"pred_class\", ylabel=\"Entropies of Predicted Labels\", \n",
    "                fig_type=\"box\", ylim=None):\n",
    "    for plot_type in [\"epoch\", \"batch\", \"layers\"]:\n",
    "        plot_df = df_with_stats.loc[df_with_stats[\"source\"].str.contains(plot_type) |\\\n",
    "                                   df_with_stats[\"source\"].str.contains(\"baseline\")]\n",
    "\n",
    "        plot_df[plot_type] = plot_df[\"source\"].str.rsplit(\"_\").str[-1]\n",
    "        if plot_type == \"epoch\":\n",
    "            plot_df[plot_type].replace({\"baseline\": 4}, inplace=True)\n",
    "            xlabel = \"Epochs\"\n",
    "        elif plot_type == \"batch\":\n",
    "            plot_df[plot_type].replace({\"baseline\": 128}, inplace=True)\n",
    "            xlabel = \"Batch Size\"\n",
    "        elif plot_type == \"layers\":\n",
    "            plot_df[plot_type].replace({\"baseline\": 1}, inplace=True)\n",
    "            xlabel = \"Layers\"\n",
    "        plot_df[plot_type] = plot_df[plot_type].astype(int)\n",
    "\n",
    "        plt.figure(figsize=(10, 5))\n",
    "        if fig_type == \"box\":\n",
    "            ax = sns.boxplot(data=plot_df, x=plot_type, y=y)\n",
    "        elif fig_type == \"violin\":\n",
    "            ax = sns.violinplot(data=plot_df, x=plot_type, y=y)\n",
    "        else:\n",
    "            raise NotImplementedError(\"fig_type must be 'box' or 'violin'\")\n",
    "        \n",
    "        ax.set_xlabel(xlabel)\n",
    "        ax.set_ylabel(ylabel)\n",
    "        ax.set_title(\"Sweeping the {} of a baseline CNN on MNIST data\".format(xlabel),\n",
    "                     fontsize=20)\n",
    "        ax.set_ylim(ylim)\n",
    "\n",
    "        mbas = plot_df[[plot_type, \"mean_balanced_accuracy\"]].drop_duplicates().sort_values(by=plot_type)\n",
    "\n",
    "        red = mpatches.Patch(color='indianred',\n",
    "                             label=\"{:.2f}\".format(mbas[\"mean_balanced_accuracy\"].values[0]))\n",
    "        blue = mpatches.Patch(color='teal', \n",
    "                              label=\"{:.2f}\".format(mbas[\"mean_balanced_accuracy\"].values[1]))\n",
    "        purple = mpatches.Patch(color='mediumslateblue', \n",
    "                                label=\"{:.2f}\".format(mbas[\"mean_balanced_accuracy\"].values[2]))\n",
    "        black = mpatches.Patch(color='dimgray',\n",
    "                               label=\"{:.2f}\".format(mbas[\"mean_balanced_accuracy\"].values[3]))\n",
    "\n",
    "        leg = ax.legend(handles=[red, blue, purple, black],\n",
    "                        bbox_to_anchor=(1, 1), loc='upper left', ncol=1)\n",
    "        leg.set_title(\"Mean Balanced Accuracy\", prop = {'size':'large'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "administrative-answer",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plots_iris(df_with_stats, y=\"pred_class\", ylabel=\"Entropies of Predicted Labels\", \n",
    "               fig_type=\"box\", ylim=None):\n",
    "    for plot_type in [\"epoch\", \"batch\", \"layers\", \"nodes\"]:\n",
    "        plot_df = df_with_stats.loc[df_with_stats[\"source\"].str.contains(plot_type) |\\\n",
    "                                   df_with_stats[\"source\"].str.contains(\"baseline\")]\n",
    "\n",
    "        plot_df[plot_type] = plot_df[\"source\"].str.rsplit(\"_\").str[-1]\n",
    "        if plot_type == \"epoch\":\n",
    "            plot_df[plot_type].replace({\"baseline\": 150}, inplace=True)\n",
    "            xlabel = \"Epochs\"\n",
    "        elif plot_type == \"batch\":\n",
    "            plot_df[plot_type].replace({\"baseline\": 5}, inplace=True)\n",
    "            xlabel = \"Batch Size\"\n",
    "        elif plot_type == \"layers\":\n",
    "            plot_df[plot_type].replace({\"baseline\": 1}, inplace=True)\n",
    "            xlabel = \"Layers\"\n",
    "        elif plot_type == \"nodes\":\n",
    "            plot_df = plot_df.loc[~plot_df[\"source\"].str.contains(\"baseline\")]\n",
    "            xlabel = \"Nodes\"\n",
    "        plot_df[plot_type] = plot_df[plot_type].astype(int)\n",
    "\n",
    "        plt.figure(figsize=(10, 5))\n",
    "        if fig_type == \"box\":\n",
    "            ax = sns.boxplot(data=plot_df, x=plot_type, y=y)\n",
    "        elif fig_type == \"violin\":\n",
    "            ax = sns.violinplot(data=plot_df, x=plot_type, y=y)\n",
    "        else:\n",
    "            raise NotImplementedError(\"fig_type must be 'box' or 'violin'\")\n",
    "        \n",
    "        ax.set_xlabel(xlabel)\n",
    "        ax.set_ylabel(ylabel)\n",
    "        ax.set_title(\"Sweeping the {} of a baseline NN on Iris data\".format(xlabel),\n",
    "                     fontsize=20)\n",
    "        ax.set_ylim(ylim)\n",
    "\n",
    "        mbas = plot_df[[plot_type, \"mean_balanced_accuracy\"]].drop_duplicates().sort_values(by=plot_type)\n",
    "\n",
    "        red = mpatches.Patch(color='indianred', \n",
    "                             label=\"{:.2f}\".format(mbas[\"mean_balanced_accuracy\"].values[0]))\n",
    "        blue = mpatches.Patch(color='teal', \n",
    "                              label=\"{:.2f}\".format(mbas[\"mean_balanced_accuracy\"].values[1]))\n",
    "        purple = mpatches.Patch(color='mediumslateblue',\n",
    "                                label=\"{:.2f}\".format(mbas[\"mean_balanced_accuracy\"].values[2]))\n",
    "        black = mpatches.Patch(color='dimgray', \n",
    "                               label=\"{:.2f}\".format(mbas[\"mean_balanced_accuracy\"].values[3]))\n",
    "\n",
    "        leg = ax.legend(handles=[red, blue, purple, black],\n",
    "                        bbox_to_anchor=(1, 1), loc='upper left', ncol=1)\n",
    "        leg.set_title(\"Mean Balanced Accuracy\", prop = {'size':'large'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "spanish-jacob",
   "metadata": {},
   "outputs": [],
   "source": [
    "SMALL_SIZE = 17\n",
    "MEDIUM_SIZE = 19\n",
    "BIGGER_SIZE = 25\n",
    "\n",
    "plt.rc('font', size=SMALL_SIZE)          # controls default text sizes\n",
    "plt.rc('axes', titlesize=SMALL_SIZE)     # fontsize of the axes title\n",
    "plt.rc('axes', labelsize=MEDIUM_SIZE)    # fontsize of the x and y labels\n",
    "plt.rc('xtick', labelsize=SMALL_SIZE)    # fontsize of the tick labels\n",
    "plt.rc('ytick', labelsize=SMALL_SIZE)    # fontsize of the tick labels\n",
    "plt.rc('legend', fontsize=MEDIUM_SIZE)   # legend fontsize\n",
    "plt.rc('figure', titlesize=BIGGER_SIZE)  # fontsize of the figure title"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "recreational-savings",
   "metadata": {},
   "source": [
    "## MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "trying-manual",
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_baseline_folder = [\"mnist_baseline\"]\n",
    "mnist_epoch_folders = [\"mnist_epoch_8\", \"mnist_epoch_12\", \"mnist_epoch_16\"]\n",
    "mnist_batch_folders = [\"mnist_batch_32\", \"mnist_batch_64\", \"mnist_batch_256\"]\n",
    "mnist_layers_folders = [\"mnist_layers_2\", \"mnist_layers_3\", \"mnist_layers_4\"]\n",
    "mnist_folder_names = mnist_baseline_folder + mnist_epoch_folders + mnist_batch_folders + mnist_layers_folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "alive-penetration",
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_df_list = []\n",
    "for mfn in mnist_folder_names:\n",
    "    dir_path = \"./data/{}\".format(mfn)\n",
    "    preds_from_mfn = retrieve_predictions(y_test=y_test_mnist, outdir=dir_path)\n",
    "    preds_from_mfn[\"source\"] = mfn\n",
    "    mnist_df_list.append(preds_from_mfn)\n",
    "mnist_all_preds = pd.concat(mnist_df_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "conventional-desert",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add balanced accuracies\n",
    "mnist_accuracies = mnist_all_preds.groupby([\"source\", \"model\"], as_index=False\n",
    "                                          ).apply(lambda x: balanced_accuracy_score(x[\"pred_class\"], \n",
    "                                                                                    x[\"real_class\"]))\n",
    "\n",
    "mnist_accuracies = mnist_accuracies.reset_index(drop=True).rename(columns={None: \"mean_balanced_accuracy\"})\n",
    "\n",
    "\n",
    "\n",
    "# *****\n",
    "# mnist_accuracies = mnist_accuracies.reset_index(drop=True).rename(columns={None: \"balanced_accuracy\"})\n",
    "\n",
    "# for plot_type in [\"epoch\", \"batch\", \"layers\"]:\n",
    "#     y=\"balanced_accuracy\"\n",
    "#     ylabel=\"Balanced Accuracy\"\n",
    "#     ylim=(-0.05, 1.05)\n",
    "#     plot_df = mnist_accuracies.loc[mnist_accuracies[\"source\"].str.contains(plot_type) |\\\n",
    "#                                mnist_accuracies[\"source\"].str.contains(\"baseline\")]\n",
    "\n",
    "#     plot_df[plot_type] = plot_df[\"source\"].str.rsplit(\"_\").str[-1]\n",
    "#     if plot_type == \"epoch\":\n",
    "#         plot_df[plot_type].replace({\"baseline\": 4}, inplace=True)\n",
    "#         xlabel = \"Epochs\"\n",
    "#     elif plot_type == \"batch\":\n",
    "#         plot_df[plot_type].replace({\"baseline\": 128}, inplace=True)\n",
    "#         xlabel = \"Batch Size\"\n",
    "#     elif plot_type == \"layers\":\n",
    "#         plot_df[plot_type].replace({\"baseline\": 1}, inplace=True)\n",
    "#         xlabel = \"Layers\"\n",
    "#     plot_df[plot_type] = plot_df[plot_type].astype(int)\n",
    "\n",
    "\n",
    "#     plt.figure(figsize=(10, 5))\n",
    "#     ax = sns.violinplot(data=plot_df, x=plot_type, y=y)\n",
    "#     ax.set_xlabel(xlabel)\n",
    "#     ax.set_ylabel(ylabel)\n",
    "#     ax.set_title(\"Sweeping the {} of a baseline CNN on MNIST data\".format(xlabel),\n",
    "#                  fontsize=20)\n",
    "#     ax.set_ylim(ylim)\n",
    "\n",
    "# *****\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "avg_mnist_accuracies = mnist_accuracies.groupby(\"source\", as_index=False).mean()\n",
    "avg_mnist_accuracies[\"mean_balanced_accuracy\"] = avg_mnist_accuracies[\"mean_balanced_accuracy\"]\n",
    "\n",
    "mnist_all_preds = pd.merge(mnist_all_preds, avg_mnist_accuracies, on=\"source\", how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "religious-technician",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mnist_all_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "manual-stuart",
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_entropies = mnist_all_preds.groupby([\"source\", \"point\"], \n",
    "                                          as_index=False).agg({\"p0\": np.mean, \"p1\": np.mean,\n",
    "                                                               \"mean_balanced_accuracy\": np.mean})\n",
    "\n",
    "mnist_entropies[\"entropy\"] = mnist_entropies.apply(lambda x: entropy([x[\"p0\"], x[\"p1\"]]), axis=1)\n",
    "\n",
    "mnist_stds = mnist_all_preds.groupby([\"source\", \"point\"], \n",
    "                                     as_index=False).agg({\"pred_class\": np.std,\n",
    "                                                          \"mean_balanced_accuracy\": np.mean})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "swedish-malpractice",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# plots_mnist(df_with_stats=mnist_entropies, fig_type=\"box\", ylim=(-0.05, 1.05),\n",
    "#              y=\"entropy\", ylabel=\"Entropies of Predicted Probabilities\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "handmade-assignment",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plots_mnist(df_with_stats=mnist_entropies, fig_type=\"violin\", ylim=(-0.05, 1.05),\n",
    "             y=\"entropy\", ylabel=\"Entropies of Predicted Probabilities\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "knowing-monte",
   "metadata": {},
   "source": [
    "## IRIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "golden-karaoke",
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_baseline_folder = [\"iris_baseline\"]\n",
    "iris_epoch_folders = [\"iris_epoch_100\", \"iris_epoch_300\", \"iris_epoch_450\"]\n",
    "iris_batch_folders = [\"iris_batch_10\", \"iris_batch_20\", \"iris_batch_40\"]\n",
    "iris_layers_folders = [\"iris_layers_2\", \"iris_layers_3\", \"iris_layers_4\"]\n",
    "iris_nodes_folders = [\"iris_nodes_3\", \"iris_nodes_4\", \"iris_nodes_5\", \"iris_nodes_6\"]\n",
    "iris_folder_names = iris_baseline_folder + iris_epoch_folders + iris_batch_folders + \\\n",
    "                    iris_layers_folders + iris_nodes_folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dried-fraud",
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_df_list = []\n",
    "for mfn in iris_folder_names:\n",
    "    dir_path = \"./data/{}\".format(mfn)\n",
    "    preds_from_mfn = retrieve_predictions(y_test=y_test_iris, outdir=dir_path)\n",
    "    preds_from_mfn[\"source\"] = mfn\n",
    "    iris_df_list.append(preds_from_mfn)\n",
    "iris_all_preds = pd.concat(iris_df_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "known-queens",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add balanced accuracies\n",
    "iris_accuracies = iris_all_preds.groupby([\"source\", \"model\"], as_index=False\n",
    "                                        ).apply(lambda x: balanced_accuracy_score(x[\"pred_class\"], \n",
    "                                                                                  x[\"real_class\"]))\n",
    "iris_accuracies = iris_accuracies.reset_index(drop=True).rename(columns={None: \"mean_balanced_accuracy\"})\n",
    "\n",
    "\n",
    "# *****\n",
    "# iris_accuracies = iris_accuracies.reset_index(drop=True).rename(columns={None: \"balanced_accuracy\"})\n",
    "\n",
    "# for plot_type in [\"epoch\", \"batch\", \"layers\", \"nodes\"]:\n",
    "#     y=\"balanced_accuracy\"\n",
    "#     ylabel=\"Balanced Accuracy\"\n",
    "#     ylim=(-0.05, 1.05)\n",
    "#     plot_df = iris_accuracies.loc[iris_accuracies[\"source\"].str.contains(plot_type) |\\\n",
    "#                                iris_accuracies[\"source\"].str.contains(\"baseline\")]\n",
    "\n",
    "#     plot_df[plot_type] = plot_df[\"source\"].str.rsplit(\"_\").str[-1]\n",
    "#     if plot_type == \"epoch\":\n",
    "#         plot_df[plot_type].replace({\"baseline\": 150}, inplace=True)\n",
    "#         xlabel = \"Epochs\"\n",
    "#     elif plot_type == \"batch\":\n",
    "#         plot_df[plot_type].replace({\"baseline\": 5}, inplace=True)\n",
    "#         xlabel = \"Batch Size\"\n",
    "#     elif plot_type == \"layers\":\n",
    "#         plot_df[plot_type].replace({\"baseline\": 1}, inplace=True)\n",
    "#         xlabel = \"Layers\"\n",
    "#     elif plot_type == \"nodes\":\n",
    "#         plot_df = plot_df.loc[~plot_df[\"source\"].str.contains(\"baseline\")]\n",
    "#         xlabel = \"Nodes\"\n",
    "#     plot_df[plot_type] = plot_df[plot_type].astype(int)\n",
    "\n",
    "\n",
    "#     plt.figure(figsize=(10, 5))\n",
    "#     ax = sns.violinplot(data=plot_df, x=plot_type, y=y)\n",
    "#     ax.set_xlabel(xlabel)\n",
    "#     ax.set_ylabel(ylabel)\n",
    "#     ax.set_title(\"Sweeping the {} of a baseline NN on Iris data\".format(xlabel),\n",
    "#                  fontsize=20)\n",
    "#     ax.set_ylim(ylim)\n",
    "\n",
    "# *****\n",
    "\n",
    "\n",
    "\n",
    "avg_iris_accuracies = iris_accuracies.groupby(\"source\", as_index=False).mean()\n",
    "\n",
    "iris_all_preds = pd.merge(iris_all_preds, avg_iris_accuracies, on=\"source\", how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vocational-mainstream",
   "metadata": {},
   "outputs": [],
   "source": [
    "# iris_all_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "assigned-hypothesis",
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_entropies = iris_all_preds.groupby([\"source\", \"point\"], \n",
    "                                          as_index=False).agg({\"p0\": np.mean, \"p1\": np.mean, \"p2\": np.mean,\n",
    "                                                               \"mean_balanced_accuracy\": np.mean})\n",
    "\n",
    "iris_entropies[\"entropy\"] = iris_entropies.apply(lambda x: entropy([x[\"p0\"], x[\"p1\"], x[\"p2\"]]), axis=1)\n",
    "\n",
    "iris_stds = iris_all_preds.groupby([\"source\", \"point\"], \n",
    "                                     as_index=False).agg({\"pred_class\": np.std,\n",
    "                                                          \"mean_balanced_accuracy\": np.mean})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "revolutionary-throw",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# plots_iris(df_with_stats=iris_entropies, fig_type=\"box\", ylim=(-0.05, 1.05),\n",
    "#            y=\"entropy\", ylabel=\"Entropies of Predicted Probabilities\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dietary-suspect",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plots_iris(df_with_stats=iris_entropies, fig_type=\"violin\", ylim=(-0.05, 1.15),\n",
    "           y=\"entropy\", ylabel=\"Entropies of Predicted Probabilities\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lesbian-twins",
   "metadata": {},
   "source": [
    "# Weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "portable-manitoba",
   "metadata": {},
   "source": [
    "## MNIST model weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "reverse-lounge",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "temp_list = []\n",
    "for mfn in mnist_folder_names:\n",
    "    weights = get_model_weights(\"./data/{}\".format(mfn))\n",
    "    weights = convert_weight_dict_to_dataframe(weights)\n",
    "    weights = weights.loc[weights[\"epoch\"] != \"1\"]\n",
    "    weight_cols = [c for c in list(weights.columns) if c not in [\"model_id\", \"epoch\", \"val_loss\"]]\n",
    "    list_of_weight_stds = [np.std(weights[col]) for col in weight_cols]\n",
    "    df = pd.DataFrame({\"source\": [mfn]*len(list_of_weight_stds), \"std\": list_of_weight_stds})\n",
    "    temp_list.append(df)\n",
    "mnist_weight_stds = pd.concat(temp_list)\n",
    "mnist_weight_stds = pd.merge(mnist_weight_stds, avg_mnist_accuracies, on=\"source\", how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "regulated-saturn",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plots_mnist(df_with_stats=mnist_weight_stds, y=\"std\", ylabel=\"STDs of Final Weights\", fig_type=\"violin\", \n",
    "            ylim=(-0.25, 1.75))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cosmetic-expense",
   "metadata": {},
   "source": [
    "## Iris Model Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lucky-clause",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_list = []\n",
    "for mfn in iris_folder_names:\n",
    "    weights = get_model_weights(\"./data/{}\".format(mfn))\n",
    "    weights = convert_weight_dict_to_dataframe(weights)\n",
    "    weights = weights.loc[weights[\"epoch\"] != \"1\"]\n",
    "    weight_cols = [c for c in list(weights.columns) if c not in [\"model_id\", \"epoch\", \"val_loss\"]]\n",
    "    list_of_weight_stds = [np.std(weights[col]) for col in weight_cols]\n",
    "    df = pd.DataFrame({\"source\": [mfn]*len(list_of_weight_stds), \"std\": list_of_weight_stds})\n",
    "    temp_list.append(df)\n",
    "iris_weight_stds = pd.concat(temp_list)\n",
    "iris_weight_stds = pd.merge(iris_weight_stds, avg_iris_accuracies, on=\"source\", how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "suffering-anderson",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plots_iris(df_with_stats=iris_weight_stds, y=\"std\", ylabel=\"STDs of Final Weights\", fig_type=\"violin\", ylim=(0,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alpha-corrections",
   "metadata": {},
   "source": [
    "# Morse Graphs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "immediate-aberdeen",
   "metadata": {},
   "source": [
    "## MNIST Morse Graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "competent-keeping",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "interesting_mnist = [\"mnist_baseline\", \"mnist_layers_2\", \"mnist_epoch_8\", \"mnist_epoch_16\"]\n",
    "\n",
    "morse_graph_dict_mnist = {}\n",
    "map_graph_dict_mnist = {}\n",
    "for im in interesting_mnist:\n",
    "    weights = get_model_weights(\"./data/{}\".format(im))\n",
    "    weights = convert_weight_dict_to_dataframe(weights)\n",
    "    \n",
    "    final_weights = weights.loc[weights[\"epoch\"] != \"1\"]    \n",
    "    weight_cols = [c for c in list(final_weights.columns) if c not in [\"model_id\", \"epoch\", \"val_loss\"]]\n",
    "    std_df = pd.DataFrame(columns=[\"weight_name\", \"std\"],\n",
    "                          data=list(zip(weight_cols, [np.std(final_weights[col]) for col in weight_cols])))\n",
    "    std_df = std_df.sort_values(by=\"std\")\n",
    "    smallest_2 = list(std_df[\"weight_name\"])[:2]\n",
    "    largest_2 = list(std_df[\"weight_name\"])[-2:]\n",
    "\n",
    "    morseg_small, mapg_small = compute_morse_graph(weights[['epoch'] + smallest_2], phase_subdiv=15)\n",
    "    morseg_large, mapg_large = compute_morse_graph(weights[['epoch'] + largest_2], phase_subdiv=15)\n",
    "    \n",
    "    morse_graph_dict_mnist[\"{}_smallest_2\".format(im)] = morseg_small\n",
    "    morse_graph_dict_mnist[\"{}_largest_2\".format(im)] = morseg_large\n",
    "    \n",
    "    map_graph_dict_mnist[\"{}_smallest_2\".format(im)] = mapg_small\n",
    "    map_graph_dict_mnist[\"{}_largest_2\".format(im)] = mapg_large\n",
    "    \n",
    "    compute_order_retraction(morseg_small, mapg_small, title=\"{}_smallest_2\".format(im))\n",
    "    compute_order_retraction(morseg_large, mapg_large, title=\"{}_largest_2\".format(im))\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "thrown-couple",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# plot distribution of two weights that you are using to see if they are actually ending up where the plots below show\n",
    "\n",
    "\n",
    "for key, value in morse_graph_dict_mnist.items():\n",
    "    print(key)\n",
    "    PlotMorseSets(value, xlim=[-2, 2], ylim=[-2, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "choice-george",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "PlotMorseGraph(morse_graph_dict_mnist[\"mnist_epoch_16_largest_2\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alpine-armstrong",
   "metadata": {},
   "source": [
    "## Iris Morse Graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "republican-defensive",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "interesting_iris = [\"iris_baseline\", \"iris_layers_2\", \"iris_epoch_450\"]\n",
    "\n",
    "morse_graph_dict_iris = {}\n",
    "map_graph_dict_iris = {}\n",
    "for ii in interesting_iris:\n",
    "    weights = get_model_weights(\"./data/{}\".format(ii))\n",
    "    weights = convert_weight_dict_to_dataframe(weights)\n",
    "    \n",
    "    final_weights = weights.loc[weights[\"epoch\"] != \"1\"]  \n",
    "    weight_cols = [c for c in list(final_weights.columns) if c not in [\"model_id\", \"epoch\", \"val_loss\"]]\n",
    "    std_df = pd.DataFrame(columns=[\"weight_name\", \"std\"],\n",
    "                          data=list(zip(weight_cols, [np.std(final_weights[col]) for col in weight_cols])))\n",
    "    std_df = std_df.sort_values(by=\"std\")\n",
    "    smallest_2 = list(std_df[\"weight_name\"])[:2]\n",
    "    largest_2 = list(std_df[\"weight_name\"])[-2:]\n",
    "\n",
    "    morseg_small, mapg_small = compute_morse_graph(weights[['epoch'] + smallest_2], phase_subdiv=15)\n",
    "    morseg_large, mapg_large = compute_morse_graph(weights[['epoch'] + largest_2], phase_subdiv=15)\n",
    "    \n",
    "    morse_graph_dict_iris[\"{}_smallest_2\".format(ii)] = morseg_small\n",
    "    morse_graph_dict_iris[\"{}_largest_2\".format(ii)] = morseg_large\n",
    "    \n",
    "    map_graph_dict_iris[\"{}_smallest_2\".format(ii)] = mapg_small\n",
    "    map_graph_dict_iris[\"{}_largest_2\".format(ii)] = mapg_large\n",
    "    \n",
    "    compute_order_retraction(morseg_small, mapg_small, title=\"{}_smallest_2\".format(ii))\n",
    "    compute_order_retraction(morseg_large, mapg_large, title=\"{}_largest_2\".format(ii))    \n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caroline-presence",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for key, value in morse_graph_dict_iris.items():\n",
    "    print(key)\n",
    "    PlotMorseSets(value, xlim=[-2, 2], ylim=[-2, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "residential-celebrity",
   "metadata": {},
   "outputs": [],
   "source": [
    "PlotMorseGraph(morse_graph_dict_iris[\"iris_baseline_smallest_2\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "general-boutique",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "domestic-tuesday",
   "metadata": {},
   "source": [
    "## Supplementary histograms of model weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cardiac-flooring",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# for im in interesting_mnist:\n",
    "#     weights = get_model_weights(\"./data/{}\".format(im))\n",
    "#     weights = convert_weight_dict_to_dataframe(weights)\n",
    "    \n",
    "#     final_weights = weights.loc[weights[\"epoch\"] != \"1\"]    \n",
    "#     weight_cols = [c for c in list(final_weights.columns) if c not in [\"model_id\", \"epoch\", \"val_loss\"]]\n",
    "#     std_df = pd.DataFrame(columns=[\"weight_name\", \"std\"],\n",
    "#                           data=list(zip(weight_cols, [np.std(final_weights[col]) for col in weight_cols])))\n",
    "#     std_df = std_df.sort_values(by=\"std\")\n",
    "#     smallest_2 = list(std_df[\"weight_name\"])[:2]\n",
    "#     largest_2 = list(std_df[\"weight_name\"])[-2:]\n",
    "    \n",
    "#     for w in smallest_2 + largest_2:\n",
    "#         std = np.std(final_weights[w])\n",
    "#         figure = plt.figure()\n",
    "#         ax = sns.distplot(final_weights[w], norm_hist=False, kde=False)\n",
    "#         ax.set_title(\"{} (Std = {:.2f})\".format(w, std))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "frequent-russia",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# for ii in interesting_iris:\n",
    "#     weights = get_model_weights(\"./data/{}\".format(ii))\n",
    "#     weights = convert_weight_dict_to_dataframe(weights)\n",
    "    \n",
    "#     final_weights = weights.loc[weights[\"epoch\"] != \"1\"]  \n",
    "#     weight_cols = [c for c in list(final_weights.columns) if c not in [\"model_id\", \"epoch\", \"val_loss\"]]\n",
    "#     std_df = pd.DataFrame(columns=[\"weight_name\", \"std\"],\n",
    "#                           data=list(zip(weight_cols, [np.std(final_weights[col]) for col in weight_cols])))\n",
    "#     std_df = std_df.sort_values(by=\"std\")\n",
    "#     smallest_2 = list(std_df[\"weight_name\"])[:2]\n",
    "#     largest_2 = list(std_df[\"weight_name\"])[-2:]\n",
    "\n",
    "#     for w in smallest_2 + largest_2:\n",
    "#         std = np.std(final_weights[w])\n",
    "#         figure = plt.figure()\n",
    "#         ax = sns.distplot(final_weights[w], norm_hist=False, kde=False)\n",
    "#         ax.set_title(\"{} (Std = {:.2f})\".format(w, std))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:deep_chaos] *",
   "language": "python",
   "name": "conda-env-deep_chaos-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
